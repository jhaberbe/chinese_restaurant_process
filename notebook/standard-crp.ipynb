{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051bfbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameshaberberger/GitHub/chinese-restaurant-process/.venv/lib/python3.12/site-packages/anndata/_core/storage.py:39: ImplicitModificationWarning: X should not be a np.matrix, use np.ndarray instead.\n",
      "  warnings.warn(msg, ImplicitModificationWarning)\n",
      "/Users/jameshaberberger/GitHub/chinese-restaurant-process/.venv/lib/python3.12/site-packages/anndata/_core/anndata.py:602: FutureWarning: You are attempting to set `X` to a matrix on a view which has non-unique indices. The resulting `adata.X` will likely not equal the value to which you set it. To avoid this potential issue, please make a copy of the data first. In the future, this operation will throw an error.\n",
      "  warnings.warn(msg, FutureWarning, stacklevel=1)\n",
      "/var/folders/2n/j06nrn2n7r524t776sngh0xr0000gr/T/ipykernel_94606/3928816788.py:6: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n",
      "  adata.X = adata.X.todense()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"/Users/jameshaberberger/GitHub/chinese-restaurant-process/data/adata.h5ad\")\n",
    "adata = adata[adata.X.sum(axis=1) > 100]\n",
    "adata.X = adata.X.todense()\n",
    "\n",
    "counts = torch.tensor(adata.X.todense())\n",
    "size_factors = (counts.sum(axis=1) / counts.sum(axis=1).mean()).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c675562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameshaberberger/GitHub/chinese-restaurant-process/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "\n",
    "class ChineseRestaurantTable:\n",
    "    \"\"\"A class representing a table in the Chinese Restaurant Process using NumPy.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.members = set()\n",
    "\n",
    "        self.concentration = torch.ones(data.shape[1])\n",
    "\n",
    "        self.last_updated_epoch = 0\n",
    "    \n",
    "    def add_member(self, index, epoch=None):\n",
    "        self.members.add(index)\n",
    "        self.concentration += self.data[index]\n",
    "\n",
    "        if epoch is not None:\n",
    "            self.last_updated_epoch = epoch\n",
    "\n",
    "    def remove_member(self, index):\n",
    "        if index in self.members:\n",
    "            self.members.remove(index)\n",
    "            self.concentration -= self.data[index]\n",
    "\n",
    "    def posterior_concentration(self, index: Union[int, torch.Tensor]):\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            return self.concentration + index\n",
    "        else:\n",
    "            return self.concentration + self.data[index]\n",
    "\n",
    "    def log_likelihood(self, index):\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            return dist.DirichletMultinomial(\n",
    "                concentration=self.concentration,\n",
    "                total_count=index.sum()\n",
    "            ).log_prob(index)\n",
    "        else:\n",
    "            return dist.DirichletMultinomial(\n",
    "                concentration=self.concentration,\n",
    "                total_count=self.data[index].sum()\n",
    "            ).log_prob(self.data[index])\n",
    "\n",
    "    def posterior_log_likelihood(self, index=None):\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            return dist.DirichletMultinomial(\n",
    "                concentration=self.posterior_concentration(index),\n",
    "                total_count=index.sum()\n",
    "            ).log_prob(index)\n",
    "        else:\n",
    "            return dist.DirichletMultinomial(\n",
    "                concentration=self.posterior_concentration(index),\n",
    "                total_count=self.data[index].sum()\n",
    "            ).log_prob(self.data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275c3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "class ChineseRestaurantProcess:\n",
    "    def __init__(self, data: np.ndarray, expected_classes: int = 10):\n",
    "        self.data = data\n",
    "\n",
    "        self.classes = {}\n",
    "        self.assignments = [-1] * data.shape[0]\n",
    "\n",
    "        self.expected_classes = expected_classes\n",
    "        self._alpha = expected_classes / np.log(data.shape[0])\n",
    "\n",
    "    def generate_new_table(self):\n",
    "        return ChineseRestaurantTable(self.data)\n",
    "\n",
    "    def add_table(self, table, index=None):\n",
    "        new_class_id = 0\n",
    "        while new_class_id in self.classes:\n",
    "            new_class_id += 1\n",
    "        self.classes[new_class_id] = table\n",
    "        if index is not None:\n",
    "            table.add_member(index)\n",
    "        return new_class_id\n",
    "\n",
    "    def remove_table(self, class_id):\n",
    "        if class_id in self.classes:\n",
    "            for member in self.classes[class_id].members:\n",
    "                self.assignments[member] = -1\n",
    "            del self.classes[class_id]\n",
    "        else:\n",
    "            raise ValueError(f\"Class ID {class_id} does not exist.\")\n",
    "\n",
    "    def run(self, epochs=1, max_classes=100, min_membership=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            for i in tqdm(np.random.permutation(self.data.shape[0])):\n",
    "                x_i = self.data[i]\n",
    "\n",
    "                # Generate new table for this round\n",
    "                crp_new = self.generate_new_table()\n",
    "\n",
    "                # Existing class log-likelihoods\n",
    "                cluster_keys = list(self.classes.keys()) + [\"new\"]\n",
    "                nlls = []\n",
    "                for k in self.classes:\n",
    "                    table = self.classes[k]\n",
    "                    log_like = table.posterior_log_likelihood(i)\n",
    "                    log_prior = np.log1p(len(table.members))\n",
    "                    nlls.append(log_like + log_prior)\n",
    "\n",
    "                # New table likelihood\n",
    "                log_new = crp_new.posterior_log_likelihood(i) + np.log(self._alpha)\n",
    "                nlls.append(log_new)\n",
    "\n",
    "                # Softmax sampling\n",
    "                probs = np.exp(nlls - np.max(nlls))  # stability\n",
    "                probs /= probs.sum()\n",
    "                sampled_idx = np.random.choice(len(probs), p=probs)\n",
    "                sampled_class = cluster_keys[sampled_idx]\n",
    "\n",
    "                # Assignment\n",
    "                if sampled_class == \"new\":\n",
    "                    new_table = self.generate_new_table()\n",
    "                    new_table.add_member(i, epoch)\n",
    "                    self.add_table(new_table, i)\n",
    "                else:\n",
    "                    self.classes[sampled_class].add_member(i, epoch)\n",
    "                    self.assignments[i] = int(sampled_class)\n",
    "\n",
    "            # After epoch: remove empty tables\n",
    "            to_remove = [k for k, v in self.classes.items() if len(v.members) <= min_membership * self.data.shape[0]]\n",
    "            for k in to_remove:\n",
    "                self.remove_table(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bc1661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/247 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [00:00<00:00, 511.93it/s]\n",
      "100%|██████████| 247/247 [00:00<00:00, 451.46it/s]\n",
      "100%|██████████| 247/247 [00:00<00:00, 432.40it/s]\n",
      "100%|██████████| 247/247 [00:00<00:00, 448.52it/s]\n",
      "100%|██████████| 247/247 [00:00<00:00, 431.03it/s]\n"
     ]
    }
   ],
   "source": [
    "crp = ChineseRestaurantProcess(counts[::500], expected_classes=10)\n",
    "crp.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4abe1",
   "metadata": {},
   "source": [
    "# Numpy Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a9126e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from typing import Union\n",
    "\n",
    "class ChineseRestaurantTable:\n",
    "    \"\"\"A class representing a table in the Chinese Restaurant Process using NumPy.\"\"\"\n",
    "\n",
    "    def __init__(self, data: np.ndarray):\n",
    "        self.data = data.astype(np.float64)\n",
    "        self.members = set()\n",
    "\n",
    "        self.concentration = np.ones(data.shape[1], dtype=np.float64)\n",
    "        self.last_updated_epoch = 0\n",
    "\n",
    "    def add_member(self, index: int, epoch: int = None):\n",
    "        self.members.add(index)\n",
    "        self.concentration += self.data[index]\n",
    "\n",
    "        if epoch is not None:\n",
    "            self.last_updated_epoch = epoch\n",
    "\n",
    "    def remove_member(self, index: int):\n",
    "        if index in self.members:\n",
    "            self.members.remove(index)\n",
    "            self.concentration -= self.data[index]\n",
    "\n",
    "    def posterior_concentration(self, index: Union[int, np.ndarray]) -> np.ndarray:\n",
    "        if isinstance(index, np.ndarray):\n",
    "            return self.concentration + index\n",
    "        else:\n",
    "            return self.concentration + self.data[int(index)]\n",
    "\n",
    "    def _log_dirichlet_multinomial(self, count: np.ndarray, concentration: np.ndarray) -> float:\n",
    "        total_count = np.sum(count)\n",
    "        return (\n",
    "            gammaln(np.sum(concentration))\n",
    "            - gammaln(np.sum(concentration) + total_count)\n",
    "            + np.sum(gammaln(concentration + count) - gammaln(concentration))\n",
    "        )\n",
    "\n",
    "    def log_likelihood(self, index: Union[int, np.ndarray]) -> float:\n",
    "        if isinstance(index, np.ndarray):\n",
    "            return self._log_dirichlet_multinomial(index, self.concentration)\n",
    "        else:\n",
    "            count = self.data[int(index)]\n",
    "            return self._log_dirichlet_multinomial(count, self.concentration)\n",
    "\n",
    "    def posterior_log_likelihood(self, index: Union[int, np.ndarray]) -> float:\n",
    "        if isinstance(index, np.ndarray):\n",
    "            conc = self.posterior_concentration(index)\n",
    "            return self._log_dirichlet_multinomial(index, conc)\n",
    "        else:\n",
    "            count = self.data[int(index)]\n",
    "            conc = self.posterior_concentration(index)\n",
    "            return self._log_dirichlet_multinomial(count, conc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "class ChineseRestaurantProcess:\n",
    "\n",
    "    def __init__(self, data: np.ndarray, expected_classes: int = 10):\n",
    "        self.data = data.astype(np.float64)\n",
    "        self.classes = {}\n",
    "        self.assignments = [-1] * data.shape[0]\n",
    "\n",
    "        self.expected_classes = expected_classes\n",
    "        self._alpha = expected_classes / np.log(data.shape[0])\n",
    "\n",
    "    def generate_new_table(self):\n",
    "        return ChineseRestaurantTable(self.data)\n",
    "\n",
    "    def add_table(self, table, index=None):\n",
    "        new_class_id = 0\n",
    "        while new_class_id in self.classes:\n",
    "            new_class_id += 1\n",
    "        self.classes[new_class_id] = table\n",
    "        if index is not None:\n",
    "            table.add_member(index)\n",
    "        return new_class_id\n",
    "\n",
    "    def remove_table(self, class_id):\n",
    "        if class_id in self.classes:\n",
    "            for member in self.classes[class_id].members:\n",
    "                self.assignments[member] = -1\n",
    "            del self.classes[class_id]\n",
    "        else:\n",
    "            raise ValueError(f\"Class ID {class_id} does not exist.\")\n",
    "\n",
    "    def run(self, epochs=1, max_classes=100, min_membership=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            for i in tqdm(np.random.permutation(self.data.shape[0])):\n",
    "                x_i = self.data[i]\n",
    "\n",
    "                # Generate new table for this round\n",
    "                crp_new = self.generate_new_table()\n",
    "\n",
    "                # Existing class log-likelihoods\n",
    "                cluster_keys = list(self.classes.keys()) + [\"new\"]\n",
    "                nlls = []\n",
    "                for k in self.classes:\n",
    "                    table = self.classes[k]\n",
    "                    log_like = table.posterior_log_likelihood(i)\n",
    "                    log_prior = np.log1p(len(table.members))\n",
    "                    nlls.append(log_like + log_prior)\n",
    "\n",
    "                # New table likelihood\n",
    "                log_new = crp_new.posterior_log_likelihood(i) + np.log(self._alpha)\n",
    "                nlls.append(log_new)\n",
    "\n",
    "                # Softmax sampling\n",
    "                probs = np.exp(nlls - np.max(nlls))  # stability\n",
    "                probs /= probs.sum()\n",
    "                sampled_idx = np.random.choice(len(probs), p=probs)\n",
    "                sampled_class = cluster_keys[sampled_idx]\n",
    "\n",
    "                # Assignment\n",
    "                if sampled_class == \"new\":\n",
    "                    new_table = self.generate_new_table()\n",
    "                    new_table.add_member(i, epoch)\n",
    "                    self.add_table(new_table, i)\n",
    "                else:\n",
    "                    self.classes[sampled_class].add_member(i, epoch)\n",
    "                    self.assignments[i] = int(sampled_class)\n",
    "\n",
    "            # After epoch: remove empty tables\n",
    "            to_remove = [k for k, v in self.classes.items() if len(v.members) <= min_membership * self.data.shape[0]]\n",
    "            for k in to_remove:\n",
    "                self.remove_table(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aecc0292",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChineseRestaurantProcess' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m crp = ChineseRestaurantProcess(counts[::\u001b[32m30\u001b[39m].numpy(), expected_classes=\u001b[32m10\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcrp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mChineseRestaurantProcess.run\u001b[39m\u001b[34m(self, epochs, max_classes, min_membership)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs=\u001b[32m1\u001b[39m, max_classes=\u001b[32m100\u001b[39m, min_membership=\u001b[32m0.01\u001b[39m):\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(np.random.permutation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m.shape[\u001b[32m0\u001b[39m])):\n\u001b[32m     37\u001b[39m             x_i = \u001b[38;5;28mself\u001b[39m.data[i]\n\u001b[32m     39\u001b[39m             \u001b[38;5;66;03m# Generate new table for this round\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'ChineseRestaurantProcess' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "crp = ChineseRestaurantProcess(counts[::30].numpy(), expected_classes=10)\n",
    "crp.run(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8943a56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      563\n",
       "0      356\n",
       "34     248\n",
       "2      213\n",
       "19     163\n",
       "1      145\n",
       "61     138\n",
       "6      116\n",
       "62     105\n",
       "7       73\n",
       "118     73\n",
       "3       67\n",
       "33      63\n",
       "42      60\n",
       "117     59\n",
       "14      58\n",
       "23      54\n",
       "110     52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(crp.assignments).value_counts()[pd.Series(crp.assignments).value_counts().gt(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67a1c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "class ChineseRestaurantProcess:\n",
    "    def __init__(self, data: np.ndarray, expected_classes: int = 10):\n",
    "        self.data = data\n",
    "\n",
    "        self.classes = {}\n",
    "        self.assignments = [-1] * data.shape[0]\n",
    "\n",
    "        self.expected_classes = expected_classes\n",
    "        self._alpha = expected_classes / np.log(data.shape[0])\n",
    "\n",
    "    def generate_new_table(self):\n",
    "        return ChineseRestaurantTable(self.data)\n",
    "\n",
    "    def add_table(self, table, index=None):\n",
    "        new_class_id = 0\n",
    "        while new_class_id in self.classes:\n",
    "            new_class_id += 1\n",
    "        self.classes[new_class_id] = table\n",
    "        if index is not None:\n",
    "            table.add_member(index)\n",
    "        return new_class_id\n",
    "\n",
    "    def remove_table(self, class_id):\n",
    "        if class_id in self.classes:\n",
    "            for member in self.classes[class_id].members:\n",
    "                self.assignments[member] = -1\n",
    "            del self.classes[class_id]\n",
    "        else:\n",
    "            raise ValueError(f\"Class ID {class_id} does not exist.\")\n",
    "\n",
    "    def run(self, epochs=1, max_classes=100, min_membership=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            for i in tqdm(np.random.permutation(self.data.shape[0])):\n",
    "                x_i = self.data[i]\n",
    "\n",
    "                # Generate new table for this round\n",
    "                crp_new = self.generate_new_table()\n",
    "\n",
    "                # Existing class log-likelihoods\n",
    "                cluster_keys = list(self.classes.keys()) + [\"new\"]\n",
    "                nlls = []\n",
    "                for k in self.classes:\n",
    "                    table = self.classes[k]\n",
    "                    log_like = table.posterior_log_likelihood(i)\n",
    "                    log_prior = np.log1p(len(table.members))\n",
    "                    nlls.append(log_like + log_prior)\n",
    "\n",
    "                # New table likelihood\n",
    "                log_new = crp_new.posterior_log_likelihood(i) + np.log(self._alpha)\n",
    "                nlls.append(log_new)\n",
    "\n",
    "                # Softmax sampling\n",
    "                probs = np.exp(nlls - np.max(nlls))  # stability\n",
    "                probs /= probs.sum()\n",
    "                sampled_idx = np.random.choice(len(probs), p=probs)\n",
    "                sampled_class = cluster_keys[sampled_idx]\n",
    "\n",
    "                # Assignment\n",
    "                if sampled_class == \"new\":\n",
    "                    new_table = self.generate_new_table()\n",
    "                    new_table.add_member(i, epoch)\n",
    "                    self.add_table(new_table, i)\n",
    "                else:\n",
    "                    self.classes[sampled_class].add_member(i, epoch)\n",
    "                    self.assignments[i] = int(sampled_class)\n",
    "\n",
    "    def predict(self, X_new: np.ndarray, min_membership: float = 0.01) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class for each sample in X_new using posterior log-likelihood.\n",
    "\n",
    "        Parameters:\n",
    "        - X_new: New data points to assign. Shape: (n_samples, n_features)\n",
    "        - min_membership: Minimum proportion of total data a class must have to be used for prediction.\n",
    "\n",
    "        Returns:\n",
    "        - assignments: np.ndarray of predicted class labels\n",
    "        \"\"\"\n",
    "        if not self.classes:\n",
    "            raise ValueError(\"No classes have been trained. Run `run()` before predicting.\")\n",
    "\n",
    "        valid_classes = {\n",
    "            k: v for k, v in self.classes.items()\n",
    "            if len(v.members) >= min_membership * self.data.shape[0]\n",
    "        }\n",
    "\n",
    "        if not valid_classes:\n",
    "            raise ValueError(\"No classes meet the minimum membership threshold.\")\n",
    "\n",
    "        assignments = []\n",
    "\n",
    "        for x in X_new:\n",
    "            nlls = []\n",
    "            keys = list(valid_classes.keys())\n",
    "            for k in keys:\n",
    "                table = valid_classes[k]\n",
    "                log_like = table.posterior_log_likelihood(x)\n",
    "                log_prior = np.log1p(len(table.members))\n",
    "                nlls.append(log_like + log_prior)\n",
    "\n",
    "            # Choose class with highest posterior log-likelihood + prior\n",
    "            best_class = keys[np.argmax(nlls)]\n",
    "            assignments.append(best_class)\n",
    "\n",
    "        return np.array(assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crp = ChineseRestaurantProcess(counts[::30].numpy(), expected_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641d3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
